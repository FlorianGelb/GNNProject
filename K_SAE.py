# -*- coding: utf-8 -*-
"""evaluation for k_SAE

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1edQtkG8nP7CC1KedpOGpIXoT6CFSxk1g
"""

# Commented out IPython magic to ensure Python compatibility.
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torchvision import transforms, datasets
from torch.utils.data import Dataset, DataLoader, random_split, Subset

import os
from PIL import Image
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np


# %matplotlib inline

# Encoder and decoder classes

class Encoder(nn.Module):
    def __init__(self, layers_dim,k):
        super(Encoder, self).__init__()
        self.layers_dim = layers_dim
        self.k=k

        layers = []
        for i in range(len(layers_dim)-2):
            layers.append(nn.Linear(layers_dim[i], layers_dim[i+1]))
            layers.append(nn.ReLU())
        layers.append(nn.Linear(layers_dim[-2], layers_dim[-1]))
        #layers.append(nn.Sigmoid())

        self.encoder = nn.Sequential(*layers)

    def forward(self, x):
        encoded = self.encoder(x)

        raw=encoded.detach().numpy()

        k=self.k
        mask = np.ones(raw.shape, dtype=bool)
        if k < raw.shape[1]:
            for i, row in enumerate(raw):
                # Find the indices of the top k elements in each row
                indices = np.argpartition(row, -k)[-k:]

                # Update the mask to set elements at indices to False
                mask[i, indices] = False
                raw[i,mask[i]]=0
        return encoded
class Decoder(nn.Module):
    def __init__(self, layers_dim):
        super(Decoder, self).__init__()
        self.layers_dim = layers_dim

        layers = []
        for i in range(len(layers_dim)-2):
            layers.append(nn.Linear(layers_dim[i], layers_dim[i+1]))
            layers.append(nn.ReLU())
        layers.append(nn.Linear(layers_dim[-2], layers_dim[-1]))
        #layers.append(nn.Sigmoid())
        self.decoder = nn.Sequential(*layers)


    def forward(self, y):
        decoded = self.decoder(y)


        return decoded

# Class for autoencoder

class Net(nn.Module):
    def __init__(self, layers,k,loss_fn=F.mse_loss, lr=1e-4, l2=0.):
        super(Net, self).__init__()
        self.layers = layers
        self.E = Encoder(layers,k)
        self.D= Decoder(layers[::-1])
        self.loss_fn = loss_fn
        self._rho_loss = None
        self._loss = None
        self.optim = optim.Adam(self.parameters(), lr=lr, weight_decay=l2)

    def forward(self, x):
        x = x.view(-1, 28*28)
        code = self.E(x)
        out = self.D(code)


        return out

    def decode(self, h):
        with torch.no_grad():
            decoded=self.D(h)
            return decoded


    def loss(self, x, target, **kwargs):
        target = target.view(-1, 28*28)
        self._loss = self.loss_fn(x, target, **kwargs)
        return self._loss

def train(epoch, models, log=None):
    train_size = len(train_loader.sampler)
    for batch_idx, (data, _) in enumerate(train_loader):
        for model in models.values():
            model.optim.zero_grad()
            inputs = data.clone().detach()
            output = model(inputs)

            loss = model.loss(output, data)
            loss.backward()
            model.optim.step()

        if batch_idx % 200 == 0:
            line = "Train Epoch: {} [{}/{} ({:.0f}%)]\tLosses ".format(
                epoch, batch_idx * len(data), train_size, 100. * batch_idx / len(train_loader))
            losses = " ".join(["{}: {:.6f}".format(k, m._loss.item()) for k, m in models.items()])
            print(line + losses)

    else:
        batch_idx += 1
        line = "Train Epoch: {} [{}/{} ({:.0f}%)]\tLosses ".format(
            epoch, batch_idx * len(data), train_size, 100. * batch_idx / len(train_loader))
        losses = " ".join(["{}: {:.6f}".format(k, m._loss.item()) for k, m in models.items()])
        if log is not None:
            for k in models:
                log[k].append((models[k]._loss, models[k]._rho_loss))
        print(line + losses)

avg_lambda = lambda l: "loss: {:.4f}".format(l)
line = lambda i, l: "{}: ".format(i) + avg_lambda(l) + "\t"

# Test function


def test(models, loader, log=None):
    test_size = len(loader.sampler)

    test_loss = {k: 0. for k in models}

    with torch.no_grad():
        for data, _ in loader:
            inputs = data.clone().detach()
            output = {k: m(inputs) for k, m in models.items()}
            for k, m in models.items():
                test_loss[k] += m.loss(output[k], data, reduction="sum").item()


    for k in models:
        test_loss[k] /= (test_size * 784)

        if log is not None:
            log[k].append((test_loss[k]))

    lines = "\n".join([line(k, test_loss[k]) for k in models]) + "\n"
    report = "Test set:\n" + lines
    print(report)


def plot_mnist(images,title, shape):
    fig = plt.figure(figsize=shape[::-1], dpi=150)
    num_images = min(len(images), shape[0] * shape[1])

    for j in range(1, num_images + 1):
        ax = fig.add_subplot(shape[0], shape[1], j)
        ax.matshow(images[j - 1, 0, :, :], cmap='gray')
        plt.xticks(np.array([]))
        plt.yticks(np.array([]))
    plt.suptitle(title)
    plt.show()

def plot(models,data_loader,shape):
  iter_data=iter(data_loader)
  data, _ = next(iter_data)
  to_plots={k: [] for k in models}
  encode={k: [] for k in models}
  for k in models:
    output = models[k](data)

    to_plot = output.view(-1, 1, 28, 28).clamp(0, 1).data.numpy()
    to_plots[k].append(to_plot)

  plot_mnist(data.data.numpy(),"Original" ,shape)
  for k in to_plots:
    plot_mnist(to_plots[k][0],f'K={k}', shape)
      
